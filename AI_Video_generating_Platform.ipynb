{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ******Avatar Video Generation Pipeline using SadTalker (Kaggle-based)******\n\nThis project generates a talking avatar video given a topic using an end-to-end GenAI pipeline. The full pipeline includes avatar creation, script generation, voice synthesis, and animation using SadTalker. Below is a structured breakdown.","metadata":{}},{"cell_type":"code","source":"\n!pip install -q diffusers transformers accelerate sentence-transformers gTTS faiss-cpu gradio\n!pip install -q git+https://github.com/CompVis/taming-transformers.git\n!pip install -q opencv-python==4.7.0.72 face_alignment imageio nest_asyncio\n\n# Step 1 Get Topic Input from User\ntopic = input(\" Enter the topic you want the avatar to explain (e.g., 'nitrogen cycle'): \").strip()\nprint(f\" Generating script for topic: {topic}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"******Avatar Image generation******","metadata":{}},{"cell_type":"markdown","source":"here  i have used only the  ","metadata":{}},{"cell_type":"code","source":"#  STEP 2: Generate Avatar Image with better facial symmetry\nfrom diffusers import StableDiffusionPipeline\nimport torch\n\ndef generate_avatar_image(topic_desc):\n    prompt = (\n        f\"high-resolution ultra-realistic photo portrait of a smiling  woman teacher, \"#give more features according to the way your avatar has to look like\n    )\n\n    negative_prompt = (\n        \" unrealistic, disfigured face, cartoonish\"\n    )\n\n    pipe = StableDiffusionPipeline.from_pretrained(\n        \"runwayml/stable-diffusion-v1-5\",\n        torch_dtype=torch.float16\n    ).to(\"cuda\")\n\n    try:\n        image = pipe(prompt=prompt, negative_prompt=negative_prompt).images[0]\n    except TypeError:\n        image = pipe(prompt=prompt).images[0]\n\n    image.save(\"avatar.jpg\")\n    print(\"üñºÔ∏è Avatar image saved as avatar.jpg\")\n    return \"avatar.jpg\"\n\n# Run it\navatar_path = generate_avatar_image(topic)\n\n\n       \n\n\n    \n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Check whether the generated avatar image is to your liking if not goto step 2 give different prompt for avatar image or any enhancements that is to be included in the image\nfrom IPython.display import Image, display  # if the face looks a little distorted ignore ,as it will be fixed in step 6 by sad talker face enhancer\ndisplay(Image(filename=\"avatar.jpg\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase I - Script Generation","metadata":{}},{"cell_type":"code","source":"#  STEP 3: Generate Script using TinyLLaMA (fixed)\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\ndef generate_script(topic):\n    tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n    model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n    model = model.to(\"cuda\")\n\n    gen = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n\n    #  Chat-style prompt works better for this model\n    prompt = f\"<|system|>\\nYou are a knowledgeable tutor.\\n<|user|>\\nExplain '{topic}' in a clear and engaging way.\\n<|assistant|>\\n\"\n\n    result = gen(prompt, max_new_tokens=500, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n\n    #  Clean generated text after the assistant tag\n    script_text = result.split(\"<|assistant|>\")[-1].strip()\n\n    if not script_text or len(script_text) < 20:\n        raise ValueError(\" Script generation failed: model returned empty or too short response.\")\n\n    with open(\"script.txt\", \"w\") as f:\n        f.write(script_text)\n    print(\" Script generated and saved as script.txt\")\n    return script_text\n\n# Try again\nscript_text = generate_script(topic)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase II  -  Voice Generation ","metadata":{}},{"cell_type":"code","source":"# STEP 4: Generate Voice using gTTS     this was earlier done using edge -tts library which generated different types of voices but edge -tts does not support kaggle \n!pip install -q gTTS\n\nfrom gtts import gTTS\nimport os\n\ndef generate_voice(script, lang=\"en\"):\n    if not script or len(script.strip()) < 10:\n        raise ValueError(\" Script is empty or too short for TTS.\")\n    tts = gTTS(text=script, lang=lang)\n    tts.save(\"audio.mp3\")\n    print(\" Audio saved as audio.mp3\")\n    return \"audio.mp3\"\n\n# Generate the audio\naudio_path = generate_voice(script_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Phase III - Avatar Generation","metadata":{}},{"cell_type":"markdown","source":"**Model implementation - Sad talker**","metadata":{}},{"cell_type":"code","source":"# STEP 5: Clone and Set Up SadTalker\n!git clone https://github.com/OpenTalker/SadTalker.git","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd SadTalker","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  Download pretrained models (for first-time use only)\n!bash scripts/download_models.sh","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install requirements\n!pip install -r requirements.txt --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install facexlib --no-deps --quiet\n!pip install basicsr --no-deps --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch==2.0.1 torchvision==0.15.2 --force-reinstall --quiet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#  Move audio and image to SadTalker folder\nimport shutil\nshutil.copy(\"/kaggle/working/audio.mp3\", \"audio.mp3\")\nshutil.copy(\"/kaggle/working/avatar.jpg\", \"avatar.jpg\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n!pip install numpy==1.23.5 --force-reinstall --quiet #mandatory step\n#After this restart kernal ie select option restart and clear cell outputs  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Right after installing numpy restart kernel and run only the cells after it(ie from  step 6)**","metadata":{}},{"cell_type":"code","source":"# step 6\n%cd /kaggle/working/SadTalker","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T04:57:23.244920Z","iopub.execute_input":"2025-06-26T04:57:23.245562Z","iopub.status.idle":"2025-06-26T04:57:23.255437Z","shell.execute_reply.started":"2025-06-26T04:57:23.245536Z","shell.execute_reply":"2025-06-26T04:57:23.254471Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/SadTalker\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Increase recursion limit (SadTalker uses deep calls) if not used maximum depth would reach and would cause error in the final output\nimport sys\nsys.setrecursionlimit(20000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:53:16.998794Z","iopub.execute_input":"2025-06-26T06:53:16.999166Z","iopub.status.idle":"2025-06-26T06:53:17.004416Z","shell.execute_reply.started":"2025-06-26T06:53:16.999137Z","shell.execute_reply":"2025-06-26T06:53:17.003521Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#  Downgrade imageio to avoid infinite recursion error - mandatory step else it would cause error\n!pip uninstall -y imageio\n!pip install imageio==2.31.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:53:06.730932Z","iopub.execute_input":"2025-06-26T06:53:06.731583Z","iopub.status.idle":"2025-06-26T06:53:11.350733Z","shell.execute_reply.started":"2025-06-26T06:53:06.731551Z","shell.execute_reply":"2025-06-26T06:53:11.349900Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: imageio 2.19.3\nUninstalling imageio-2.19.3:\n  Successfully uninstalled imageio-2.19.3\nCollecting imageio==2.31.1\n  Downloading imageio-2.31.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio==2.31.1) (1.23.5)\nRequirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio==2.31.1) (11.2.1)\nDownloading imageio-2.31.1-py3-none-any.whl (313 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: imageio\nSuccessfully installed imageio-2.31.1\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# final step it might take 5 or 10 mintues ti gnerate video\n!python inference.py \\\n  --driven_audio audio.mp3 \\\n  --source_image avatar.jpg \\\n  --result_dir results \\\n  --still \\\n  --enhancer gfpgan         # used for enhacing the avatar\n  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-26T06:53:42.499825Z","iopub.execute_input":"2025-06-26T06:53:42.500327Z","iopub.status.idle":"2025-06-26T07:24:50.284516Z","shell.execute_reply.started":"2025-06-26T06:53:42.500305Z","shell.execute_reply":"2025-06-26T07:24:50.283669Z"}},"outputs":[{"name":"stdout","text":"using safetensor as default\n3DMM Extraction for source image\nlandmark Det:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.51it/s]\n3DMM Extraction In Video:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 13.59it/s]\nmel:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2637/2637 [00:00<00:00, 26340.32it/s]\naudio2exp:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 264/264 [00:00<00:00, 464.66it/s]\nFace Renderer:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1319/1319 [14:34<00:00,  1.51it/s]\nThe generated video is named results/2025_06_26_06.53.58/avatar##audio.mp4\nface enhancer....\nFace Enhancer:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2637/2637 [15:21<00:00,  2.86it/s]\nThe generated video is named results/2025_06_26_06.53.58/avatar##audio_enhanced.mp4\nThe generated video is named: results/2025_06_26_06.53.58.mp4\n\u001b[0m","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**The video will be generated in the directory ie kaggle/working/Sadtalker/results which can be accesssed on the right side bar, click on results from that directory and u can find .mp4 video, download it**","metadata":{}}]}